{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Techniques in Matrix Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7.3 The Jacobi and Gauss-Siedel Iterative Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobi Method\n",
    "$$x^{(k)}_i=\\sum^n_{\\substack{j\\neq i \\\\ j=1}}\\biggl(-\\frac{a_{ij}x^{(k)}_{j}}{a_{ii}}\\biggr)+\\frac{b_i}{a_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobi(A:np.ndarray, x:np.ndarray, b:np.ndarray, iter:int, tol:float=1e-5) -> np.ndarray:\n",
    "    x_ = np.copy(x)\n",
    "    for iter in range(iter):\n",
    "        prev_x = np.copy(x_)\n",
    "        for idx in range(A.shape[0]):\n",
    "            mask = np.arange(len(x_)) != idx\n",
    "            x_[idx] = 1 / (A[idx][idx]) * (b[idx] - np.sum(A[idx][mask] @ prev_x[mask]))\n",
    "        # if np.linalg.norm(x_ - prev_x) < tol:\n",
    "        #     print(\"Iteration stopped, norm difference < tolerance.\")\n",
    "        #     break\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauss-Siedel Method\n",
    "$$x^{(k)}_i=\\frac{1}{a_{ii}}\\biggl[\n",
    "    -\\sum^{i-1}_{j=1}(a_{ij}x^{(k)}_j)-\\sum^{n}_{j=i+1}(a_{ij}x^{(k-1)}_j)+b_i\n",
    "\\biggr]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussSeidel(A:np.ndarray, x:np.ndarray, b:np.ndarray, iter:int, tol:float=1e-5) -> np.ndarray:\n",
    "    x_ = np.copy(x)\n",
    "    for iter in range(iter):\n",
    "        prev_x = np.copy(x_)\n",
    "        for idx in range(A.shape[0]):\n",
    "            mask = np.arange(len(x_)) != idx\n",
    "            x_[idx] = 1 / (A[idx][idx]) * (b[idx] - np.sum(A[idx][mask] @ x_[mask]))\n",
    "        # if np.linalg.norm(x_ - prev_x) < tol:\n",
    "        #     print(\"Iteration stopped, norm difference < tolerance.\")\n",
    "        #     break\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7.4 Relaxation Techniques for Solving Linear Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sucessive Over-Relaxation Method\n",
    "$$x^{(k)}_i=(1-\\omega)x^{(k-1)}_i+\\frac{\\omega}{a_{ii}}\\biggl[\n",
    "    -\\sum^{i-1}_{j=1}(a_{ij}x^{(k)}_j)-\\sum^{n}_{j=i+1}(a_{ij}x^{(k-1)}_j)+b_i\n",
    "\\biggr]$$\n",
    "where $\\omega > 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR(A:np.ndarray, x:np.ndarray, b:np.ndarray, iter:int, omega=1.5, tol:float=1e-5) -> np.ndarray:\n",
    "    x_ = np.copy(x)\n",
    "    for iter in range(iter):\n",
    "        prev_x = np.copy(x_)\n",
    "        for idx in range(A.shape[0]):\n",
    "            mask = np.arange(len(x_)) != idx\n",
    "            x_[idx] = (1 - omega) * prev_x[idx] + (omega / (A[idx][idx]) * (b[idx] - np.sum(A[idx][mask] @ x_[mask])))\n",
    "        # if np.linalg.norm(x_ - prev_x) < tol:\n",
    "        #     print(\"Iteration stopped, norm difference < tolerance.\")\n",
    "        #     break\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7.6 The Conjugate Gradient Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConjugateGradient(A:np.ndarray, x:np.ndarray, b:np.ndarray, v:np.ndarray, tol=1e-6) -> np.ndarray:\n",
    "    x_ = x.copy().astype(float)\n",
    "    for k in range(v.shape[0]):\n",
    "        t = np.dot(v[:, k], b - A @ x_) / (np.dot(v[:, k], A @ v[:, k]))\n",
    "        x_ += (t * v[:, k]).reshape(x_.shape)\n",
    "        if np.linalg.norm(b - A @ x_) < tol:\n",
    "            return x_\n",
    "    return x_\n",
    "\n",
    "def ConjugateGradient_(A:np.ndarray, x:np.ndarray, b:np.ndarray, tol=1e-6) -> np.ndarray:\n",
    "    x_ = x.copy().astype(float)\n",
    "    r = b - A @ x_\n",
    "    v = r.copy()\n",
    "    for _ in range(v.shape[0]):\n",
    "        print(x_)\n",
    "        if np.linalg.norm(v) < tol:\n",
    "            return x_\n",
    "        s = 1 / np.dot(r.flatten(), r.flatten())\n",
    "        t = np.dot(r.flatten(), r.flatten()) / (np.dot(v.flatten(), A @ v))\n",
    "        x_ += (t * v).reshape(x_.shape)\n",
    "        r -= t * A @ v\n",
    "        if np.linalg.norm(r) < tol:\n",
    "            return x_\n",
    "        s *= np.dot(r.flatten(), r.flatten())\n",
    "        v = r + s * v\n",
    "    return x_\n",
    "\n",
    "def PreconditionConjugateGradient(A:np.ndarray, C:np.ndarray, x:np.ndarray, b:np.ndarray, tol=1e-6) -> np.ndarray:\n",
    "    x_ = x.copy().astype(float)\n",
    "    r = b - A @ x_\n",
    "    w = C @ r\n",
    "    v = C.T @ w\n",
    "    for _ in range(v.shape[0]):\n",
    "        if np.linalg.norm(v) < tol:\n",
    "            return x_\n",
    "        s = 1 / np.dot(w.flatten(), w.flatten())\n",
    "        t = np.dot(w.flatten(), w.flatten()) / (np.dot(v.flatten(), A @ v))\n",
    "        x_ += (t * v).reshape(x_.shape)\n",
    "        r -= t * A @ v\n",
    "        if np.linalg.norm(r) < tol:\n",
    "            return x_\n",
    "        w = C @ r\n",
    "        s *= np.dot(w.flatten(), w.flatten())\n",
    "        v = C.T @ w + s * v\n",
    "    return x_\n",
    "\n",
    "# A = np.array([\n",
    "#     [4, 3, 0],\n",
    "#     [3, 4, -1],\n",
    "#     [0, -1, 4],\n",
    "# ])\n",
    "# b = np.array([\n",
    "#     [24], [30], [-24]\n",
    "# ])\n",
    "# v = np.array([\n",
    "#     [1, -3 / 4, -3 / 7],\n",
    "#     [0, 1, 4 / 7],\n",
    "#     [0, 0, 1]\n",
    "# ])\n",
    "# x = np.array([\n",
    "#     [0], [0], [0]\n",
    "# ])\n",
    "# ConjugateGradient(A, x, b, v), ConjugateGradient_(A, x, b), PreconditionConjugateGradient(A, np.eye(3), x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobi Method\n",
      "[[ 7.859706  ]\n",
      " [ 0.42292595]\n",
      " [-0.07359236]\n",
      " [-0.54064405]\n",
      " [ 0.01062616]]\n",
      "Gauss-Seidel Method\n",
      "[[ 7.8597126 ]\n",
      " [ 0.42292643]\n",
      " [-0.07359223]\n",
      " [-0.540643  ]\n",
      " [ 0.01062616]]\n",
      "SOR\n",
      "[[ 7.859713  ]\n",
      " [ 0.4229264 ]\n",
      " [-0.07359224]\n",
      " [-0.54064304]\n",
      " [ 0.01062616]]\n",
      "Conjugate Gradient\n",
      "0\n",
      "[[0.00300832]\n",
      " [0.00601665]\n",
      " [0.00902497]\n",
      " [0.0120333 ]\n",
      " [0.01504162]]\n",
      "1\n",
      "[[0.04647092]\n",
      " [0.09363862]\n",
      " [0.12985331]\n",
      " [0.18422967]\n",
      " [0.00632678]]\n",
      "2\n",
      "[[0.127921  ]\n",
      " [0.26835779]\n",
      " [0.05196309]\n",
      " [0.493859  ]\n",
      " [0.00484866]]\n",
      "3\n",
      "[[0.3059927 ]\n",
      " [0.49147673]\n",
      " [0.05351802]\n",
      " [0.38951203]\n",
      " [0.00577334]]\n",
      "4\n",
      "[[ 7.85971308]\n",
      " [ 0.42292641]\n",
      " [-0.07359224]\n",
      " [-0.54064302]\n",
      " [ 0.01062616]]\n",
      "[[ 7.85971308]\n",
      " [ 0.42292641]\n",
      " [-0.07359224]\n",
      " [-0.54064302]\n",
      " [ 0.01062616]]\n",
      "Preconditioned Conjugate Gradient\n",
      "0\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "1\n",
      "[[2.79266985]\n",
      " [0.27926699]\n",
      " [0.0279267 ]\n",
      " [0.27926699]\n",
      " [0.00398953]]\n",
      "2\n",
      "[[ 5.43426173]\n",
      " [ 0.67245844]\n",
      " [-0.03550208]\n",
      " [-0.24152014]\n",
      " [ 0.01235105]]\n",
      "3\n",
      "[[ 7.77113748]\n",
      " [ 0.43706384]\n",
      " [-0.05561341]\n",
      " [-0.54481047]\n",
      " [ 0.01144523]]\n",
      "4\n",
      "[[ 7.85968827]\n",
      " [ 0.42288329]\n",
      " [-0.07359878]\n",
      " [-0.540632  ]\n",
      " [ 0.01064344]]\n",
      "[[ 7.85968827]\n",
      " [ 0.42288329]\n",
      " [-0.07359878]\n",
      " [-0.540632  ]\n",
      " [ 0.01064344]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [0.2, 0.1, 1, 1, 0],\n",
    "    [0.1, 4, -1, 1, -1],\n",
    "    [1, -1, 60, 0, -2],\n",
    "    [1, 1, 0, 8, 4],\n",
    "    [0, -1, -2, 4, 700]\n",
    "])\n",
    "\n",
    "b = np.array([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3],\n",
    "    [4],\n",
    "    [5]\n",
    "])\n",
    "\n",
    "x = np.array([\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(\"Jacobi Method\")\n",
    "print(Jacobi(A, x, b, 100))\n",
    "\n",
    "print(\"Gauss-Seidel Method\")\n",
    "print(GaussSeidel(A, x, b, 100))\n",
    "\n",
    "print(\"SOR\")\n",
    "print(SOR(A, x, b, 100, 1.25, 0.01))\n",
    "\n",
    "print(\"Conjugate Gradient\")\n",
    "print(ConjugateGradient_(A, x, b, 0.01))\n",
    "\n",
    "print(\"Preconditioned Conjugate Gradient\")\n",
    "print(PreconditionConjugateGradient(A, 1 / np.sqrt(np.diag(A)) * np.eye(A.shape[0]), x, b, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## Theorem 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
